# # -*- coding: utf-8 -*-
# """NLP_Trustpilot.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1xT3aGrkpAHX_n_g63mIZVJ171JMsdadP
# """

# from os import link
# from fastapi.encoders import jsonable_encoder
# import pandas as pd
# from bs4 import BeautifulSoup
# import urllib.request
# import string
# from starlette.responses import JSONResponse
# from pydantic import BaseModel
# from typing import Dict

# dict_cat = [
#     {
#         'category': 'aliments',
#         'link': ' /categories/food_beverages_tobacco',

#     },

#     {
#         'category': 'animaux',
#         'link': '/categories/animals_pets',
#     },

#     {
#         'category': 'argent',
#         'link': '/categories/money_insurance',
#     },
#     {
#         'category': 'beauté',
#         'link': '/categories/beauty_wellbeing',
#     },
#     {
#         'category': 'construction',
#         'link': '/categories/construction_manufactoring',
#     },
#     {
#         'category': 'education',
#         'link': '/categories/education_training',
#     },
#     {
#         'category': 'tech',
#         'link': '/categories/electronics_technology',
#     },
#     {
#         'category': 'evenements',
#         'link': '/categories/events_entertainment',
#     },
#     {
#         'category': 'loisir_artisanat',
#         'link': '/categories/hobbies_crafts',
#     },
#     {
#         'category': 'maison_jardin',
#         'link': '/categories/home_garden',
#     },
#     {
#         'category': 'média',
#         'link': '/categories/media_publishing',
#     },
#     {
#         'category': 'restau_bar',
#         'link': '/categories/restaurants_bars',
#     },
#     {
#         'category': 'santé',
#         'link': '/categories/health_medical',
#     },
#     {
#         'category': 'services',
#         'link': '/categories/utilities',
#     },
#     {
#         'category': 'services_domicile',
#         'link': '/categories/home_services',
#     },

#     {
#         'category': 'services_entreprise',
#         'link': '/categories/business_services',
#     },
#     {
#         'category': 'juridique_admin',
#         'link': '/categories/legal_services_government',
#     },
#     {
#         'category': 'services_publics',
#         'link': '/categories/public_local_services',
#     },
#     {
#         'category': 'mode',
#         'link': '/categories/shopping_fashion',
#     },
#     {
#         'category': 'sport',
#         'link': '/categories/sports',
#     },
#     {
#         'category': 'voyage',
#         'link': '/categories/travel_vacation',
#     },
#     {
#         'category': 'véhicule_transport',
#         'link': '/categories/vehicles_transportation',
#     },
# ]




from starlette.responses import JSONResponse


def choose_category(category_name: str):
    for category in dict_cat:
        if (category['category'] == category_name):
            return {'category': category_name, 'link': category['link']}
    return {"error": "There is no category call :" + category_name}

trustpilot = f'https://fr.trustpilot.com{category_link}?numberofreviews=500'
web_page = urllib.request.urlopen(trustpilot)
category_soup = BeautifulSoup(web_page, 'html.parser')
list_company = []
for element in category_soup.find_all('a', {'class': 'link_internal__YpiJI link_wrapper__LEdx5'}):
    company = element.get('href')
    if '/review/' in company and company not in list_company:
        list_company.append(company)
    print(list_company)


def scrapping(category_name: str):
    choose_category(category_name)
    for category in dict_cat:
        if (category['category'] == category):
            return category['category'], category['link']
    return {"error": "There is no category call :" + category_name}

    category_link = category['link']
    trustpilot = f'https://fr.trustpilot.com{category_link}?numberofreviews=500'
    web_page = urllib.request.urlopen(trustpilot)
    category_soup = BeautifulSoup(web_page, 'html.parser')
    list_company = []
    for element in category_soup.find_all('a', {'class': 'link_internal__YpiJI link_wrapper__LEdx5'}):
            company = element.get('href')
            if '/review/' in company and company not in list_company:
                list_company.append(company)

            print(list_company)

page_number = [1, 2]
list_url = []
    for company_url in list_company:
        for page in page_number:
            url = f'https://fr.trustpilot.com{company_url}' + f'?page={page}'
            list_url.append(url)

    list_soup = []

    for x in list_url:
        web_page = urllib.request.urlopen(x)
        base_soup = BeautifulSoup(web_page, 'html.parser')
        list_soup.append(base_soup)

    voir contenu
    print(soup.prettify())

    list_dates = []
    list_reviews = []
    list_ratings = []

    for soup in list_soup:
        for element in soup.find_all('div', {'class': 'review-content'}):
            date = element.find(
                'p', {'class': 'review-content__dateOfExperience'})
            list_dates.append(date)
            text = element.find('p', {'class': 'review-content__text'})
            if text is not None:
                list_reviews.append(text.getText())
            else:
                title = element.find(
                    'a', {'class': 'link link--large link--dark'}).getText()
                list_reviews.append(title)
            rating = element.find(
                'div', {'class': 'star-rating star-rating--medium'})
            list_ratings.append(rating)

    df = pd.DataFrame(
        {'date': list_dates, 'review': list_reviews, 'rating': list_ratings})

    JSONResponse(content=df)

#choose_category('aliments')
